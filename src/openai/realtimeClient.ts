import WebSocket from 'ws';
import { type RealtimeAudioMessageHandler, type RealtimeErrorHandler, type RealtimeVoiceClient } from '../realtime/types.js';

export interface OpenAIRealtimeConfig {
  apiKey: string;
  model: string;
  voice: string;
  temperature: number;
  topP: number;
  systemInstructions: string;
}

export class OpenAIRealtimeClient implements RealtimeVoiceClient {
  private ws: WebSocket | null = null;
  private readonly config: OpenAIRealtimeConfig;
  private messageHandler: RealtimeAudioMessageHandler | null = null;
  private errorHandler: RealtimeErrorHandler | null = null;
  private isReady = false;
  private audioSendCount = 0;

  constructor(config: OpenAIRealtimeConfig) {
    this.config = config;
  }

  async connect(): Promise<void> {
    if (this.ws?.readyState === WebSocket.OPEN) {
      console.log('æ—¢ã«OpenAI Realtime APIã«æ¥ç¶šã—ã¦ã„ã¾ã™ã€‚');
      return;
    }

    const url = 'wss://api.openai.com/v1/realtime?model=' + encodeURIComponent(this.config.model);
    console.log('OpenAI Realtime APIã«æ¥ç¶šä¸­...');

    return new Promise((resolve, reject) => {
      try {
        const headers = {
          Authorization: `Bearer ${this.config.apiKey}`,
          'OpenAI-Beta': 'realtime=v1'
        };

        this.ws = new WebSocket(url, { headers });

        this.ws.on('open', () => {
          console.log('âœ“ OpenAI Realtime APIã«æ¥ç¶šã—ã¾ã—ãŸã€‚');
          resolve();
        });

        this.ws.on('message', (raw) => {
          this.handleMessage(raw);
        });

        this.ws.on('error', (error) => {
          console.error('âŒ OpenAI WebSocketã‚¨ãƒ©ãƒ¼:', error.message);
          if (this.errorHandler) {
            this.errorHandler(error);
          }
          reject(error);
        });

        this.ws.on('close', (code, reason) => {
          console.log(`OpenAI WebSocketæ¥ç¶šãŒé–‰ã˜ã‚‰ã‚Œã¾ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰: ${code}, ç†ç”±: ${reason || 'ãªã—'}`);
          this.ws = null;
          this.isReady = false;
        });
      } catch (error) {
        reject(error);
      }
    });
  }

  startConversation(): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.warn('âš  OpenAIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚');
      return;
    }

    if (this.isReady) {
      console.log('ğŸ’¬ OpenAIä¼šè©±ã‚’é–‹å§‹ï¼ˆVADãƒ¢ãƒ¼ãƒ‰ã§è‡ªå‹•å¿œç­”ï¼‰');
      // ã‚µãƒ¼ãƒãƒ¼VADãŒæœ‰åŠ¹ãªå ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã™ã¨è‡ªå‹•çš„ã«å¿œç­”ãŒç”Ÿæˆã•ã‚Œã¾ã™
      // å¿…è¦ã«å¿œã˜ã¦åˆå›æŒ¨æ‹¶ã‚’ä¿ƒã™ã“ã¨ã‚‚ã§ãã¾ã™
      console.log('   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã™ã¨ã€OpenAIãŒè‡ªå‹•çš„ã«å¿œç­”ã—ã¾ã™');
    } else {
      console.warn('âš  OpenAIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã¾ã åˆæœŸåŒ–ä¸­ã®ãŸã‚ã€startConversationã¯å¾…æ©Ÿã—ã¾ã™ã€‚');
    }
  }

  sendAudio(audioData: string, mimeType: string = 'audio/pcm'): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.warn('âš  OpenAI WebSocketãŒé–‹ã„ã¦ã„ã¾ã›ã‚“ã€‚');
      return;
    }

    if (!this.isReady) {
      console.warn('âš  OpenAIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæº–å‚™ã§ãã¦ã„ãªã„ãŸã‚ã€éŸ³å£°ã‚’é€ä¿¡ã§ãã¾ã›ã‚“ã€‚');
      return;
    }

    // OpenAI Realtime APIã¯ audio ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ç›´æ¥base64æ–‡å­—åˆ—ã‚’æœŸå¾…ã—ã¾ã™
    const message = {
      type: 'input_audio_buffer.append',
      audio: audioData
    };

    this.ws.send(JSON.stringify(message));

    this.audioSendCount++;
    if (this.audioSendCount === 1) {
      console.log('âœ“ OpenAIã¸ã®éŸ³å£°é€ä¿¡ã‚’é–‹å§‹ã—ã¾ã—ãŸ');
    } else if (this.audioSendCount % 100 === 0) {
      console.log(`âœ“ OpenAIã¸ ${this.audioSendCount}å€‹ã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸ`);
    }
  }

  onAudioMessage(handler: RealtimeAudioMessageHandler): void {
    this.messageHandler = handler;
  }

  onError(handler: RealtimeErrorHandler): void {
    this.errorHandler = handler;
  }

  close(): void {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
    this.isReady = false;
    console.log('OpenAI Realtime APIæ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸã€‚');
  }

  isConnected(): boolean {
    return Boolean(this.ws && this.ws.readyState === WebSocket.OPEN && this.isReady);
  }

  getPreferredInputMimeType(): string {
    return 'audio/pcm';
  }

  getPreferredSampleRate(): number {
    // OpenAI Realtime APIã¯24kHzã‚’ã‚µãƒãƒ¼ãƒˆ
    return 24000;
  }

  getProviderLabel(): string {
    return 'OpenAI';
  }

  private handleMessage(raw: WebSocket.Data): void {
    let message: any;
    try {
      message = JSON.parse(raw.toString());
    } catch (error) {
      console.error('âŒ OpenAIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è§£æã«å¤±æ•—:', error);
      return;
    }

    // ğŸ” å…¨ã¦ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    console.log('ğŸ“¨ OpenAIã‚¤ãƒ™ãƒ³ãƒˆ:', message.type);

    // ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
    if (message.type === 'session.created') {
      this.isReady = true;
      console.log('âœ“ OpenAIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒä½œæˆã•ã‚Œã¾ã—ãŸ');
      console.log('  - ãƒ¢ãƒ‡ãƒ«:', message.session?.model);
      console.log('  - ãƒœã‚¤ã‚¹:', message.session?.voice);
      console.log('  - å…¥åŠ›éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:', message.session?.input_audio_format);
      console.log('  - å‡ºåŠ›éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:', message.session?.output_audio_format);
      console.log('  - ã‚¿ãƒ¼ãƒ³æ¤œå‡º:', message.session?.turn_detection);
      this.configureSession();
      return;
    }

    // ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°
    if (message.type === 'session.updated') {
      console.log('âœ“ OpenAIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ');
      return;
    }

    // éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡
    if (message.type === 'response.audio.delta') {
      if (message.delta && this.messageHandler) {
        console.log('ğŸ”Š OpenAIéŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡:', message.delta.length, 'æ–‡å­—');
        this.messageHandler(message.delta);
      }
      return;
    }

    // éŸ³å£°æ›¸ãèµ·ã“ã—å—ä¿¡
    if (message.type === 'response.audio_transcript.delta') {
      console.log('ğŸ“ OpenAIæ›¸ãèµ·ã“ã—:', message.delta);
      return;
    }

    // å¿œç­”å®Œäº†
    if (message.type === 'response.done') {
      console.log('âœ“ OpenAIå¿œç­”å®Œäº†');
      return;
    }

    // å…¥åŠ›éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚³ãƒŸãƒƒãƒˆ
    if (message.type === 'input_audio_buffer.committed') {
      console.log('âœ“ éŸ³å£°å…¥åŠ›ãŒã‚³ãƒŸãƒƒãƒˆã•ã‚Œã¾ã—ãŸ');
      return;
    }

    // ä¼šè©±ã‚¢ã‚¤ãƒ†ãƒ ä½œæˆ
    if (message.type === 'conversation.item.created') {
      console.log('âœ“ ä¼šè©±ã‚¢ã‚¤ãƒ†ãƒ ä½œæˆ:', message.item?.type);
      return;
    }

    // ã‚¨ãƒ©ãƒ¼
    if (message.type === 'error') {
      const err = new Error(`OpenAI Error ${message.error?.code}: ${message.error?.message}`);
      console.error('âŒ', err.message);
      if (this.errorHandler) {
        this.errorHandler(err);
      }
      return;
    }

    // ãã®ä»–ã®ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    if (message.type !== 'response.audio.delta') {
      console.log('  ğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°:', JSON.stringify(message, null, 2).substring(0, 500));
    }
  }

  private configureSession(): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      return;
    }

    console.log('ğŸ”§ OpenAIã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¨­å®šä¸­...');
    const sessionConfig = {
      type: 'session.update',
      session: {
        modalities: ['text', 'audio'],
        instructions: this.config.systemInstructions,
        voice: this.config.voice,
        input_audio_format: 'pcm16',
        output_audio_format: 'pcm16',
        input_audio_transcription: {
          model: 'whisper-1'
        },
        turn_detection: {
          type: 'server_vad',
          threshold: 0.5,
          prefix_padding_ms: 300,
          silence_duration_ms: 500
        },
        temperature: this.config.temperature,
        max_response_output_tokens: 4096
      }
    };

    console.log('  - ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º:', this.config.systemInstructions.substring(0, 100) + '...');
    console.log('  - ãƒœã‚¤ã‚¹:', this.config.voice);
    console.log('  - VADæœ‰åŠ¹: ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰');
    this.ws.send(JSON.stringify(sessionConfig));
  }
}


